import optuna
import lightgbm as lgb
from sklearn.metrics import accuracy_score
import numpy as np

# Define class weights
class_weights = {0: 1, 1: 5, 2: 10}  # Adjust these weights based on your class imbalance

def objective(trial):
    # Define the hyperparameters to tune
    param = {
        'objective': 'multiclass',
        'num_class': 3,
        'metric': 'multi_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': trial.suggest_int('num_leaves', 20, 150),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 10.0),
        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 10.0),
    }

    # Create dataset for LightGBM with class weights
    weight = np.array([class_weights[cls] for cls in y_train])
    train_data = lgb.Dataset(X_train, label=y_train, weight=weight)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

    # Train the model
    model = lgb.train(param, train_data, valid_sets=[val_data], early_stopping_rounds=10, verbose_eval=False)
    
    # Predict and evaluate
    y_pred = model.predict(X_val, num_iteration=model.best_iteration)
    y_pred_class = y_pred.argmax(axis=1)
    accuracy = accuracy_score(y_val, y_pred_class)
    
    return accuracy
#########
study = optuna.create_study(direction='maximize')  # Maximizing accuracy
study.optimize(objective, n_trials=100)

print(f'Best trial: {study.best_trial.params}')


##########
# Extract the best parameters
best_params = study.best_trial.params

# Add fixed parameters that are not tuned
best_params['objective'] = 'multiclass'
best_params['num_class'] = 3
best_params['metric'] = 'multi_logloss'
best_params['boosting_type'] = 'gbdt'

# Create dataset for LightGBM with class weights
weight = np.array([class_weights[cls] for cls in y_train])
train_data = lgb.Dataset(X_train, label=y_train, weight=weight)
val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

# Train the final model
final_model = lgb.train(best_params, train_data, valid_sets=[val_data], early_stopping_rounds=10, verbose_eval=False)

# Predict and evaluate the final model
y_pred = final_model.predict(X_val, num_iteration=final_model.best_iteration)
y_pred_class = y_pred.argmax(axis=1)
accuracy = accuracy_score(y_val, y_pred_class)

print(f'Final model accuracy: {accuracy}')

